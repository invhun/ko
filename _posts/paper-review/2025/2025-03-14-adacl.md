---
title: "[논문 리뷰] Discovering Clone Negatives via Adaptive Contrastive Learning for Image-Text Matching"
author: invhun
date: 2025-02-09 01:10:00 +0900
categories: [Paper Review, Multimodal Learning]
tags: [Text-Image, Multimodal Learning, Representation Learning, Contrastive Learning, Clone Negative, Retrieval]
math: true
pin: false
---

> Discovering Clone Negatives via Adaptive Contrastive Learning for Image-Text Matching  
> ICLR 2025   
> **Renjie Pan**, Jihao Dong, Hua Yang   
> Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai Key Lab of Digital Media Processing and Transmission, Shanghai Jiao Tong University   
> [[paper](https://openreview.net/pdf/38d33e5b5d68c5695433f21ea53fcd4a094452ce.pdf)]

# 1. Abstract & Introduction

### 기존 연구 문제점
![fig1](https://1drv.ms/i/c/af5642aec05791fb/IQSQJ-AJHzg2RpQWI9qlgic0AVrCWW0iF6un1rrADGr82oI?width=1179&height=456)

- 이미지-텍스트 쌍이 아님에도 불구하고, 의미적으로 관련된 텍스트, 유사한 시각적 단서를 가지는 경우가 많고, 이런 경우 사실 상 구분이 불가능함
- 그림 1의 $$ \lbrace I_1, T_2 \rbrace $$의 경우 일반적인 hard negative sample의 예시로, 일정 부분의 내용이 매치되지 않는 경우이며, 널리 탐구되었음
- 그림 1의 $$ \lbrace I_1, T_3 \rbrace $$의 경우 의미적으로 일치하지만, $$T_1$$이 더 밀접한 대응 관계를 보여주기 때문에, $$T_3$$은 최적의 매칭이 아님, 저자는 이를 clone negative로 정의하였음
- 이러한 시나리오에서 기존 방법(Triplet ranking loss, InfoNCE 등)은 clone negative 문제를 해결하기 어려움

### 제안 방법
- clone negative를 활용하고 효과적으로 구분할 수 있는 Adaptive Contrastive Learning(AdaCL)을 제안함
- 두 개의 마진 매개변수를 사용하여, positive 샘플의 응집력 강화, clone negative supervision 도입
- 가우시안 판별 분석을 통해, 학습 없이 동적으로 앵커를 선택하는 방식 제안
- 캡셔닝으로 clone negative를 생성하여, weak supervised 방식에 적용가능함을 보임

# 3. Adaptive Contrastive Learning
![fig2](https://1drv.ms/i/c/af5642aec05791fb/IQTPaxp4srUmQaibDe_YrXLnAbpzE6ahWi_aFQtTK_nX0t8?width=1174&height=548)


### 3.1. Preliminary
![fo1](https://1drv.ms/i/c/af5642aec05791fb/IQSX4tJYPtrKQ7LvMR6kLQHdAeel3gS79x0JEKRRcRHepfc?width=794&height=97)
![fo2](https://1drv.ms/i/c/af5642aec05791fb/IQRxbmLt9S0pTKsbt4k8ULz8Ac2fh7uTRD2KsfpovjNdW94?width=931&height=106)

- 간략하게, softmax로 정규화된 probability와 이를 활용해서 cross-entropy, 즉 InfoNCE로스 식을 뜻함

### 3.2. Adaptive Contrastive Learning

![fo3](https://1drv.ms/i/c/af5642aec05791fb/IQQeAg8DqRyzRaJ9_2Um-r1HAdgapXsXLmi2VisvNPYp9uQ?width=963&height=105)
- clone negative를 잘 구별하기 위하여, 1번 식에 scailing, shifting을 담당하는 2가지 margin parameter를 추가하여 확률을 조정하고, 이를 최종 infoNCE로스 식에 사용함

![fo4](https://1drv.ms/i/c/af5642aec05791fb/IQQozz6KItHgRZvjClAa5t-PAb9MDHlMGOryiKvSOgeRArM?width=861&height=87)
![fo5](https://1drv.ms/i/c/af5642aec05791fb/IQSZaTRnyg2xSbm-cCLfV5_cAT2FkWo_mb-ZBAhkI2vBd5w?width=709&height=72)
![fo6](https://1drv.ms/i/c/af5642aec05791fb/IQQ-vWUR7YqpTpSd7IQRB3EDAQ5LBVsA9y3-GflKQjIOOVs?width=817&height=78)
- 배치 내 clone negative를 대표하는 anchor를 선택하였다고 가정하였을 때, anchor의 확률을 높이는 것은 모델이 샘플들을 잘 구별하는 방향을 뜻함
- 즉, 5번 식처럼, anchor의 이미지와 텍스트의 유사도가 1에 가까워질수록, $$\hat{p}_u$$ 또한, 1에 가까워진다고 할 수 있음
- 따라서 이 방향으로 모델이 학습되도록 최종적으로 6번 식을 통해서, m1과 m2를 조정하고, 조정된 m1과 m2를 사용해 InfoNCE로스를 계산


### 3.3. Anchor Selection

![fo7](https://1drv.ms/i/c/af5642aec05791fb/IQQhpYp3sfS2R7AiH5diZ9m1AfCeZITgnoE8H-IcxsxZIws?width=827&height=109)
- salient anchor를 선택하여, potential clone negative의 supervision을 control 하는 것이 목적
- 이를 위해 각 샘플 별 salient score를 측정
- 높은 salient score 샘플을 $$S_{sln}$$이라 명명, 즉 1개의 positive, M개의 salient negative로 구성됨
- 반대로 낮은 salient score 샘플을 $$S_{cln}$$ 이라 명명, 이는 1개의 positive, M개의 potential clone negative로 구성됨


![fo8](https://1drv.ms/i/c/af5642aec05791fb/IQQ-1FhGnIU-TLv1LEa44Z6IARAMir6REp5c3UYISGfDfcU?width=991&height=95)
- 단순히 salient score로 potential clone negative를 선택이 가능하지만, 이는 over-fitting을 유발함을 발견하였음
- 따라서, 저자는 Gaussian Discriminant Analysis (GDA)를 적용함, 이는 전통적인 분류 기법으로, 데이터가 가우시안 분포를 따른다는 가정 하에 (즉, 각 클래스가 동일한 공분산), 각 클래스의 평균과 분산을 계산하여 확률로 분류
- 특정 similiary score가 Clone negative임을 나타내는 확률을 베이즈 정리를 통해 계산할 수 있음. 

![fo9](https://1drv.ms/i/c/af5642aec05791fb/IQQiOBw9_MKpQo-n83iLYvtWAXcSvNuvQYKIFSdMAblJrqY?width=877&height=111)
- 이때 각 클래스의 데이터는 가우시안 분포를 따르기 떄문에 다음과 같이 계산할 수 있음
$$p(s | C) = \frac{1}{\sqrt{2\pi \sigma_c^2}} \exp\left(-\frac{(s - \mu_c)^2}{2\sigma_c^2}\right)$$,  
$$p(s | \bar{C}) = \frac{1}{\sqrt{2\pi \sigma_{\bar{c}}^2}} \exp\left(-\frac{(s - \mu_{\bar{c}})^2}{2\sigma_{\bar{c}}^2}\right)$$
- 논문에서 명확하지 않게 표기되어 있지 않은데, $$S_{sln}이 \mu_c, \sigma_c$$를 $$S_{cln}이 \mu_{\bar{c}}, \sigma_{\bar{c}}$$ 를 나타내는 것으로 보이지만, 이것이 반대로 기록되었다고 판단됨.

![fo10](https://1drv.ms/i/c/af5642aec05791fb/IQQA_aAihJoNQJluj5wPCrckASZeSXLxAHj_7ndxKAH3PQ4?width=792&height=57)
![fo11](https://1drv.ms/i/c/af5642aec05791fb/IQROqJQgjPk-SrWdEqS9VDNRAQLeos2uNfsevV0LR-yu0qA?width=1027&height=55)
- 이를 통해, 각 similarity score를 통해, clone negative를 선택
- 선택된 clone negative similiart score와 긍정 페어의 similarity score의 차이의 중간값을 anchor로 지정
- 이를 통해 anchor는 모든 potential clone negative와 positive 사이의 평균 discrepancy를 나타냄.
- anchor를 사용해, m1과 m2를 조정하고, 이들은 최종 로스를 조정

![algo1](https://1drv.ms/i/c/af5642aec05791fb/IQT071oCi6rGS5ySQVbU20HmAXpgU4_3Q66NdtsSMVeUcJI?width=1063&height=676)
- 전체 과정은 위 알고리즘에 나타나 있음

### 3.4 Weakly-Supervised Matching with Pseudo Captions

- 기존 인터넷에서 수집된 데이터셋은, 내재된 노이즈가 많고, 서로 다른 이미지를 설명하는 텍스트가 비슷할 수 있음
- 이러한 특성이 기존의 벤치마크에서는 간과되고 있음
- 저자는 4가지 이미지 캡셔닝 방법(BLIP, GIT, BLIP-2, CoCa)를 사용하여 Flickr30K 데이터셋의 이미지에 대한 Pseudo 캡션을 생성하고, 이로 교체함
- 이를 사용해 Weakly-Supervised 매칭을 수행


# 4. Experiments

### 4.1. Setup
#### Dataset
- Flickr30K, MS-COCO

#### Architecture
- ResNet + BiGRU
- Faster R-CNN + BiGRU
- Faster R-CNN + BERT

#### Training Details
- GPU: Four NVIDIA Tesla V100
- Batchsize: 64
- Optimizer: Adam
- Max Sentence Length: 32
- Region on Faster R-CNN: 36
- Embedding Dimension: 256
- Momentum memory bank: 4096, 0.99 coefficient


### 4.2. Results on Image-Text Matching
![t1](https://1drv.ms/i/c/af5642aec05791fb/IQRfKw9GtKhLSoxzWjzdXwvsAcdmEBDWltQZtmu77tOxpyI?width=1187&height=788)
![t2](https://1drv.ms/i/c/af5642aec05791fb/IQSuXatkBp6XRJcbs_Gx-LNkAQwGBFrFgy81f0ixQkm3Rsk?width=581&height=398)
- 직관적으로 예상되듯, R@1 성능 향상에 비해, R@5, R@10의 향상은 저조하거나, 부족한 경우가 있음. 하지만 문제가 될 수준은 아님
- Flickr30K, COCO와 같이 작은 데이터셋으로만 테스트하였다고 리뷰어가 지적하였고, 저자는 CC3M, CC12M에 대한 성능을 추가적으로 실험하여 기록함
- 하지만, 같은 리뷰어(최종 점수 3점)는 CC12M이 CC3M에 비해 성능 상승이 낮은 것을 지적하였으나, Area Chair는 저자에 의해 답변 되었다고 판단하였음

### 4.3. Results of Weakly-Supervised Image-Text Matching with Pseudo Captions
![t3](https://1drv.ms/i/c/af5642aec05791fb/IQT64N_6zb-1RL80K7W748CbAfh8Y3yDN3RsM-5tvHLljk0?width=583&height=402)
- Captioner로 생성된 annotation으로 경쟁력 있는 성능을 달성 할 수 있음을 보여줌

### 4.4. Ablation Study

#### Verification of modules.
![t4](https://1drv.ms/i/c/af5642aec05791fb/IQQJDM7BF9nhT6ud6psQp6R4AaiyEi8sYial6Vlyb06pahk?width=620&height=343)
- 저자의 제안 방식이 가장 좋은건 놀랍지 않으나, Contrastive loss가 Triplet Rank loss보다 낮은 것이 의아함

#### Analysis of anchor selection methods.
![t5](https://1drv.ms/i/c/af5642aec05791fb/IQQZUDd6snEjRoB1ypXN9DNHAWh5gw0b2sg519JeKUuOUO8?width=537&height=274)
- 최대값은 가장 나쁜 결과를 보임
- 최소 선택은 직관적으로 적절하지만, 모델이 잘못 추론할 가능성을 간과할 수 있음
- 따라서 평균 logit을 반영하는 median이 가장 효과적

#### Analysis of adaptive tuning process.
![fig3](https://1drv.ms/i/c/af5642aec05791fb/IQSDz1uiZgZeSIKOPr7h-46NAWaccHzLQy-P9qU1JKt9MLo?width=1033&height=361)
- 10epoch즈음에서 수렴하며 안정됨
- 10epoch에서 t-SNE 시각화를 비교하였을 때, AdaCL이 더 나은 클러스터링 성능을 보임

### 4.5. Qualitative Analysis and Visualization
![fig4](https://1drv.ms/i/c/af5642aec05791fb/IQR-AApAsZnNS7cZgNCZB_TQAenS9E8-08eSZliZxNEtN0g?width=1182&height=445)
![fig5](https://1drv.ms/i/c/af5642aec05791fb/IQSQoNJkEgsGSYnvWyhEWdIKAQNYR7hjsT6jH7FqDukuArM?width=1175&height=497)
- Clone negative의 유사도를 생각보다 많이 떨어뜨림, 그럼에도 불구하고, R@5, R@10 성능이 보존됨이 신기함

# Review
- 위에서 언급한 리뷰어의 CC3M, CC12M 말고도, 같은 리뷰어의 Computational Cost 지적도 있었고, 저자는 대응하였으나 리뷰어는 3차 답변없이 3점을 고수하였음. 하지만 Area Chair가 저자가 잘 대응하였다고 판단하여 Accept된 논문. Chair의 권한이 크고 역할이 중요함을 확인할 수 있었음. 그리고 리뷰어 운이 어쩔수 없이 중요하다...
- Clone negative 라는 개념을 제안한 논문으로, 추가적인 외부나 사전지식 없이 로스만을 조정하여 이를 해결한 것이 대단함
- R5, R10 성능이 보존된 것으로 저자의 방식에서 지적받을 만한 부분은 거의 커버가 된 것 같음
- 동영상 데이터셋도 마찬가지로 다른 비디오간 상당히 유사한 쿼리 캡션이 많이 존재하기도 하며, Negative sample의 분류는 확실하게 더 복잡하게 얽힐것으로 보이며, 이 부분은 아직 탐구가 부족함. 하지만 이를 위해서는 좀 더 고품질로 정제된 데이터셋이 필요할 것으로 생각됨