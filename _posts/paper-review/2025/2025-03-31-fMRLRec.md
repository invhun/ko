---
title: "[논문 리뷰] Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation"
author: invhun
date: 2025-04-01 16:00:00 +0900
categories: [Paper Review, Multimodal Learning]
tags: [Recommendation System, Multimodal Learning, Matryoshka Learning, Embedding Compression]
math: true
pin: false
---

> Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation   
> EMNLP findinds 2024   
> **Yueqi Wang**, **Zhenrui Yue**, Huimin Zeng, Dong Wang, Julian McAuley   
> University of California, Berkeley and University of Illinois Urbana-Champaign and University of California, San Diego    
> [[paper](https://aclanthology.org/2024.findings-emnlp.786.pdf)], [[github](https://github.com/yueqirex/fMRLRec)]

# 1. Abstract & Introduction

### 기존 연구 문제점
- 대규모 데이터에서 다중 모달 지식을 추천 시스템에 통합하는데, 메모리 요구 사항이 크고 복잡한 모델 설정이 필요
- 다양한 추천 시나리오에서 성능과 효율성을 위한 item representation의 세분화가 필요함
- 최적의 세분화를 찾기 위해 Grid search, adaptive search heuristic이 사용되지만, 비효율적이며 높은 학습 비용이 초래됨

### 제안 방법
-  full-scale Matryoshka representation learning for multimodal recommendation (fMRLRec)를 제안
- 한번의 학습으로 다양한 크기의 모델을 생성할 수 있도록 설계
- 작은 벡터표현을 큰 표현에 포함시키는 방식으로 메모리 비용 감소, 효율적인 선형 변환을 통해 작은 가중치와 활성화함수 또한 큰 것에 포함
- 기존의 state-space modeling가 융합하여 효율성과 성능을 모두 달성


# 2. Related Works

## 2.1 Multimodal Recommendations
- 최근 언어, 멀티모달 모델이 추천 시스템에 적용되어, 사용자 선호와 항목 특성을 이해하는데 사용됨
- 현재 방식은 사전학습된 모델을 활용하여, 항목 표현을 개선하거나, 검색된 항목의 순위를 재조정함
- 현재 모델은 유연한 항목 속성이나 모달리티에 맞춰져 있지 않으며, 확장 가능한 모델 크기와 효율적인 추론을 위해 최적화되어있지 않음

# 3. Methodologies

## 3.1. Problem Statement

![fo1](https://1drv.ms/i/c/af5642aec05791fb/IQSSlNB7RmQdR5KD72Gwp4QUAeqRYJHUKNXj88vBaYaXSFs?width=421&height=60)
- multimodal sequential recommendation에 초점을 둔 연구
- 유저 집합 $$U = \lbrace u_1, u_2, ..., u_{|U|}\rbrace$$, 아이템 집합 $$ V = \lbrace v_1, v_2, ..., v_{|V|} \rbrace$$이 주어질 때
- 유저가 아이템과 상호작용한 시퀀스는 시간 순서대로 $$S_u = [v^{(u)}\_1, v^{(u)}\_2, ..., v^{(u)}\_{n}] $$로 나타나며, n은 시퀀스 길이
- 이 task의 목적은 시퀀스 $$S_u$$가 주어질 때, 다음 상호작용 아이템 $$v^{(u)}\_{n+1}$$ 의 확률을 최대화 하는 것

## 3.2. Full-Scale Matryoshka Representation Learning for Recommendation

![fig1](https://1drv.ms/i/c/af5642aec05791fb/IQQ8bIj6ebjcTZ4nIQuAzbDtAaj2W4lgYBiZvBtcz6OePF8?width=603&height=581)
- 이유는 모르겠지만 상당히 어렵게 작성을 해놓았다. 결국 핵심 내용은 한줄로 요약된다
- 입력 데이터 $$X$$와 전체 가중치 $$W$$가 있고, 출력값이 $$XW$$라면, 슬라이스된(작은) 데이터 $$X^J$$는 마찬가지로 슬라이스된 가중치 $$W^J$$와 곱해서 출력값을 계산하는 형태가 되며, 작은 모델이 큰 모델에 포함된 형태이다. 또한 각 모델들이 같이 학습이 되어, 추론 떄 독립적으로 사용이 가능하다.
- 마스킹은 별것 없이, Weight에서 필요없는 부분에 패딩을 채워놓은것이 전부
- 기존 마트료시카와 큰 차이는 없다.

## 3.3. Framework

![fig2](https://1drv.ms/i/c/af5642aec05791fb/IQQweUoywT0vQprfG16o-4J8AaY8qKB6eJYmDk1lj6H4imk?width=1142&height=442)

![fo6](https://1drv.ms/i/c/af5642aec05791fb/IQRG9TUXmnEGRa19_F0ttHK0AZbeo7XA1lpaCLwd7fUkHJo?width=578&height=54)
![fo7](https://1drv.ms/i/c/af5642aec05791fb/IQSxqstzB74qSK9y5M7MfMzSAXTyinoEpm5JAy03wMjMhe0?width=560&height=50)
- 항목의 title, price, brand, category를 합쳐서 텍스트로, 항목 이미지를 이미지 속성으로 사용
- 각각 인코딩 후, concat, projection을 수행

- 이후 메인 아키텍처로는 LRU를 사용하는데, 저자는 우수한 성능 그리고 RNN과 self-attention에 비해 낮은 학습/추론 코스트로 인해 LRU를 사용하였다고 한다.
- LRU는 ICML 2023에 구글 딥마인드에서 낸 논문으로 자세한 내용은 생략 [[LRU](https://proceedings.mlr.press/v202/orvieto23a.html)]

![fo13](https://1drv.ms/i/c/af5642aec05791fb/IQQ4bm_hx_lTQ6NA0M0UPekTAYfk57WCA6A9VyHIUhXoK3c?width=423&height=71)
![fo14](https://1drv.ms/i/c/af5642aec05791fb/IQRwon5aJ4szTbVnljblV9k8AbXvEEmxvt1wsEhHDLH49t0?width=612&height=150)
- 마지막 레이어 z와 상품 임베딩과의 유사도를 계산
- 이를 원 마트료시카 로스와 같은 방식으로 각 차원별로 로스 계산, 합을 수행함

# 4. fMRLRec Memory Efficiency

- 제안 방식과 독립적으로 모델들을 학습한 방식과의 메모리 효율 비교를 수행
- 독립 방식의 경우 각 차원별 모델 크기의 파라미터와 활성화함수를 계산하고 이를 합산함. 이렇게 비교하는 것이 맞나..

# 5. Experimental Setup

## 5.1. Datasets
![t1](https://1drv.ms/i/c/af5642aec05791fb/IQQFSEu77PqqTJ2pcWSrn7rHAYKRZKs90k_ivVL0KFk75kg?width=612&height=262)
- Amazon.com에서 흔히 사용되는 네 가지 Sparsity한 벤치마크 데이터셋을 사용
    - beauty
    - Clothing, Shoes & Jewelty
    - Sports & Outdoors
    - Toys & Games

- 전처리 과정
    - 입력 시퀀스는 시간 순서에 따라 구성, 다섯번 미만으로 등장한 사용자와 아이템 제외
    - 텍스트 특성: 제목, 가격, 브랜드, 카테고리
    - 시각적 특성: 아이템의 사진
    - 메타데이터 없는 아이템은 제외

- Implementation details
    - 임베딩 크기: [64, 128, 256, 512, 1024, 2048]
    -  fMRLRec-LRU 레이어 수: [1, 2, 4, 8]

- Metrics
    - NDCG@K
        - 추천된 항목의 순위에서 각 항목의 관련성을 부여, 일반적으로 0에서 1까지의 값
        - Discounted Cumulative Gain (DCG) 계산 $$ DCG_k = \sum_{i=1}^{k} \frac{rel_i}{\log_2(i + 1)}$$
        - DCG를 실제 Ideal DCG로 나눠서 계산, $$NDCG_K = \frac{DCG_K}{IDCG_K}$$
    - Recall@K
        - $$\frac{TP}{AP}$$
        - TP: 추천 목록에 포함된 사용자가 선호하는 항목의 수
        - AP: 사용자가 선호하는 전체 항목의 수


# 6. Experimental Results

## 6.1. Main Performance Analysis

![t2](https://1drv.ms/i/c/af5642aec05791fb/IQRoyas5oQc2Q6yjYJ6VgJ5XAVGaPDPTDnVT4stlted3U2s?width=1235&height=837)
- Sports R@10을 제외하면 최고의 성능을 달성
- Recall보다 더 어려운 평가지표 NDCG에서 더 큰 성능 향상을 보여줌
- Clothing, SPorts와 같은 sparse한 데이터셋에서의 이점을 보여줌

## 6.2. fMRLRec Model-Series Performance

![fig3](https://1drv.ms/i/c/af5642aec05791fb/IQRxKJe5lfbwRY4LQxI07oTnATECMRpjmSJvDhvk2XvMNb0?width=609&height=765)
- Matryoshka 논문에서 제시한 독립적으로 학습된 모델과의 차이를 보이는게 아닌, 이 논문에선 단순히 학습한 모델에서 모델 크기별 성능 추이만을 보임
- 분석이 부족한 것 같다.


## 6.4. Ablation Study

![t3](https://1drv.ms/i/c/af5642aec05791fb/IQT2olb5k0DbRI_CkuV8QSu6AaVR-mvi0R5YklgawD43RhM?width=1244&height=458)
- language -> image 순으로 기여가 큼
- 둘 다 제외한, 즉 임의로 초기화한 거의 실험은 어떻게 한거지..?

## 8. Limitations
- Click rate prediction, Multi-baskte recommendation과 같은 다른 recommendation task에 대해서는 실험하지 않았음
- 더 넓게는 제안 fMRL 방식이 다른 머신러닝 분야에도 적용 가능성이 있음, 이러한 모델과 데이터의 규모가 크게 변동하는 분야에서 fMRL의 성능을 탐구하지 않았음
- 향후 연구로 위 이론적 분석과 실험을 수행할 계획임

# Review
- Recommendation system의 경우 예전에 오셨던 교수님의 설명을 들었을 때, Retrieval과 유사한 부분이 있다고 생각하였었는데, 분야 자체는 비슷하다고 할 수 있으나, 연구 되고 있는 방향에는 차이가 큰 것 같음
- Recommendation system은 확실히 좀 더 application 측면의 성격이 강한 것으로 보임
- 이 분야에서 임베딩 압축에 따른 효율성에 대해 첫 시도한 논문이라는 점에서 의의가 있으며, 기존 MRL과 달리 weight단에서도 축소된다는 차이가 있음, 하지만 실험 분석에는 아쉬움이 남음